{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ec709d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "#  LICENSE:\n",
    "#    This file is distributed under the Creative Commons\n",
    "#    Attribution-NonCommercial 4.0 International License (CC BY-NC 4.0).\n",
    "#    https://creativecommons.org/licenses/by-nc/4.0/\n",
    "#\n",
    "#    You are free to:\n",
    "#      • Share — copy and redistribute the material in any medium or format\n",
    "#      • Adapt — remix, transform, and build upon the material\n",
    "#    under the following terms:\n",
    "#      • Attribution — You must give appropriate credit, provide a link to\n",
    "#        the license, and indicate if changes were made.\n",
    "#      • NonCommercial — You may not use the material for commercial purposes.\n",
    "#\n",
    "#\n",
    "#  DISCLAIMER:\n",
    "#    This code is provided “AS IS,” without warranties or conditions of any kind,\n",
    "#    express or implied. Use it at your own risk.\n",
    "# -----------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355a9bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a2e4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set environment\n",
    "root_path = \"/path-to-dataset/MM5_Dataset\"\n",
    "\n",
    "# When using Label Studio\n",
    "ls_base_url='http://192.168.0.1:8080'\n",
    "ls_api_key='your-API-key'\n",
    "project_id_rgb = 1 \n",
    "project_id_t   = 2\n",
    "project_id_uv  = 3\n",
    "\n",
    "import sys\n",
    "import importlib\n",
    "\n",
    "modules_to_clear = ['mm5_ls_utils']  # Add the modules you want to clear from cache when updating the .py file\n",
    "for module in modules_to_clear:\n",
    "    if module in sys.modules:\n",
    "        del sys.modules[module]\n",
    "        importlib.invalidate_caches()\n",
    "\n",
    "inc_dir = root_path+'/scripts'\n",
    "if inc_dir not in sys.path:\n",
    "    sys.path.append(inc_dir)\n",
    "\n",
    "from mm5_ls_utils import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e3aea3",
   "metadata": {},
   "source": [
    "## Read camera calibration data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f729efd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "from mm5_ls_utils import read_calibration_params\n",
    "\n",
    "# Usage\n",
    "filename = root_path+'/MM5_CALIBRATION/def_stereocalib_THERM.yml'\n",
    "ts_calibration_data = read_calibration_params(filename,'stereo')\n",
    "# print(ts_calibration_data)\n",
    "\n",
    "filename = root_path+'/MM5_CALIBRATION/def_uvcam_ori.yml'\n",
    "uc_calibration_data = read_calibration_params(filename,'cam')\n",
    "# print(ts_calibration_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a1945fc",
   "metadata": {},
   "source": [
    "## Export GT maps from label-studio projects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c342dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import json\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from label_studio_sdk.client import LabelStudio\n",
    "from mm5_ls_utils import rle_to_mask  # Ensure rle_to_mask is defined in mm5_ls_utils\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# Configuration (Assumes these variables are defined elsewhere in your code)\n",
    "# -------------------------------------------------------------------------\n",
    "# ls_base_url = \"YOUR_LABEL_STUDIO_BASE_URL\"\n",
    "# ls_api_key = \"YOUR_LABEL_STUDIO_API_KEY\"\n",
    "# root_path = \"YOUR_DESIRED_ROOT_PATH\"\n",
    "# project_id_rgb = YOUR_PROJECT_ID\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# Initialize Label Studio client\n",
    "# -------------------------------------------------------------------------\n",
    "client = LabelStudio(\n",
    "    base_url=ls_base_url,\n",
    "    api_key=ls_api_key\n",
    ")\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# Fetch the project using the RGB project ID\n",
    "# -------------------------------------------------------------------------\n",
    "project = client.projects.get(project_id_rgb)\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# Define the destination folder for output images\n",
    "# -------------------------------------------------------------------------\n",
    "destination_folder = os.path.join(root_path, \"ANNO_V\")\n",
    "if not os.path.exists(destination_folder):\n",
    "    os.makedirs(destination_folder)\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# Prepare data structures\n",
    "#   label_mapping: Maps label names to unique numeric IDs\n",
    "#   image_masks:   Stores \"object\" and \"class\" masks per image\n",
    "#   metadata:      Stores metadata about each labeled instance\n",
    "# -------------------------------------------------------------------------\n",
    "label_mapping = {}\n",
    "image_masks = {}\n",
    "metadata = {}\n",
    "max_id = 0\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# Counters\n",
    "#   annotation_count: Count of all brush label annotations\n",
    "#   processed_tasks_count: How many tasks (images) actually had annotations\n",
    "# -------------------------------------------------------------------------\n",
    "annotation_count = 0\n",
    "processed_tasks_count = 0\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# Fetch all tasks (with annotations) from the project\n",
    "# -------------------------------------------------------------------------\n",
    "tasks = client.tasks.list(project=project.id, fields='all')\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# Process each task and its annotations\n",
    "# -------------------------------------------------------------------------\n",
    "for task in tasks:\n",
    "    if task.annotations:\n",
    "        # If there's at least one annotation, increment processed tasks\n",
    "        processed_tasks_count += 1\n",
    "\n",
    "        # Extract the original filename and task ID\n",
    "        filename = task.data.get('image', '')\n",
    "        \n",
    "        # Extract a shorter, processed filename\n",
    "        segments = filename.split('/')\n",
    "        short_filename = segments[-1]\n",
    "        processed_filename = (\n",
    "            f\"{short_filename.split('-')[1].split('_')[0]}_\"\n",
    "            f\"{short_filename.split('.')[-2].split('_')[-1]}\"\n",
    "        )\n",
    "        \n",
    "        # Extract the numeric image ID from the processed filename\n",
    "        img_id = int(processed_filename.split('_')[0])\n",
    "        \n",
    "        # Keep track of how many times a label appears (for instance IDs)\n",
    "        instance_id_counters = {}\n",
    "        \n",
    "        # ---------------------------------------------------------------------\n",
    "        # Each task can have multiple annotations; process each annotation\n",
    "        # ---------------------------------------------------------------------\n",
    "        for annotation in task.annotations:\n",
    "            for result in annotation['result']:\n",
    "                if result['type'] == 'brushlabels':\n",
    "                    # Count this annotation\n",
    "                    annotation_count += 1\n",
    "\n",
    "                    label_name = result['value']['brushlabels'][0]\n",
    "                    label_id = result['id']\n",
    "                    \n",
    "                    # If it's a new label, assign a new integer ID\n",
    "                    if label_name not in label_mapping:\n",
    "                        max_id += 1\n",
    "                        label_mapping[label_name] = max_id\n",
    "                    \n",
    "                    # Increment (or initialize) the counter for this label_name\n",
    "                    if label_name not in instance_id_counters:\n",
    "                        instance_id_counters[label_name] = 1\n",
    "                    else:\n",
    "                        instance_id_counters[label_name] += 1\n",
    "                    \n",
    "                    # Get the instance ID specific to this label\n",
    "                    instance_id = instance_id_counters[label_name]\n",
    "                    \n",
    "                    # Decode the run-length encoding (RLE) into a binary mask\n",
    "                    rle = result['value']['rle']\n",
    "                    binary_mask = rle_to_mask(rle, \n",
    "                                              result['original_height'], \n",
    "                                              result['original_width'])\n",
    "                    \n",
    "                    # Initialize the image mask entries if needed\n",
    "                    if processed_filename not in image_masks:\n",
    "                        image_masks[processed_filename] = {\n",
    "                            'object': np.zeros(binary_mask.shape, dtype=np.uint8),\n",
    "                            'class': np.zeros(binary_mask.shape, dtype=np.uint8)\n",
    "                        }\n",
    "                    \n",
    "                    # Set object mask = instance_id\n",
    "                    image_masks[processed_filename]['object'][binary_mask == 255] = instance_id\n",
    "                    # Set class mask = label_mapping[label_name]\n",
    "                    image_masks[processed_filename]['class'][binary_mask == 255] = label_mapping[label_name]\n",
    "                    \n",
    "                    # Update metadata for this instance\n",
    "                    meta_key = f\"{img_id}_{label_mapping[label_name]}_{instance_id}\"\n",
    "                    metadata[meta_key] = {\n",
    "                        'label_id': label_mapping[label_name],\n",
    "                        'ls_label_id': label_id,\n",
    "                        'instance_id': instance_id,\n",
    "                        'img_id': img_id,\n",
    "                        'label_name': label_name,\n",
    "                        'file_name': processed_filename\n",
    "                    }\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# Save each generated mask to disk\n",
    "# -------------------------------------------------------------------------\n",
    "for name, masks in image_masks.items():\n",
    "    # (Optional) Fix specific naming if needed\n",
    "    name = name.replace(\"8dyn\", \"\")  # Example rename; remove if unnecessary\n",
    "    \n",
    "    object_image_path = os.path.join(destination_folder, f\"{name}_object.bmp\")\n",
    "    class_image_path = os.path.join(destination_folder, f\"{name}_class.bmp\")\n",
    "    \n",
    "    # Convert arrays to images and save\n",
    "    Image.fromarray(masks['object']).save(object_image_path)\n",
    "    Image.fromarray(masks['class']).save(class_image_path)\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# Sort the label mapping by the assigned ID for consistency\n",
    "# -------------------------------------------------------------------------\n",
    "sorted_label_items = sorted(label_mapping.items(), key=lambda x: x[1])\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# Save the label mapping to CSV\n",
    "# -------------------------------------------------------------------------\n",
    "csv_filename = os.path.join(destination_folder, 'label_mapping.csv')\n",
    "with open(csv_filename, 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['ID', 'Label Name'])\n",
    "    for label, label_id in sorted_label_items:\n",
    "        writer.writerow([label_id, label])\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# Save the label mapping to JSON\n",
    "# -------------------------------------------------------------------------\n",
    "json_filename = os.path.join(destination_folder, 'label_mapping.json')\n",
    "with open(json_filename, 'w') as file:\n",
    "    json_data = {label: label_id for label, label_id in sorted_label_items}\n",
    "    json.dump(json_data, file, indent=4)\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# Save class names (label names) to a plain text file\n",
    "# -------------------------------------------------------------------------\n",
    "classes_filename = os.path.join(destination_folder, 'classes.txt')\n",
    "with open(classes_filename, 'w') as file:\n",
    "    for label, _label_id in sorted_label_items:\n",
    "        file.write(label + '\\n')\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# Save the metadata about each labeled instance to JSON\n",
    "# -------------------------------------------------------------------------\n",
    "json_meta_filename = os.path.join(destination_folder, 'label_instances.json')\n",
    "with open(json_meta_filename, 'w') as file:\n",
    "    json.dump(metadata, file, indent=4)\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "print(f\"Finished. Processed {processed_tasks_count} frames (tasks) \"\n",
    "      f\"with {annotation_count} brush label annotations.\")\n",
    "\n",
    "# print(label_mapping)\n",
    "# print (sorted_items)\n",
    "# json_data = json.dumps(metadata, indent=4)\n",
    "# print(json_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6144f4f7",
   "metadata": {},
   "source": [
    "## Alignment example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10f12d4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "       \n",
    "from mm5_ls_utils import (\n",
    "    auto_tone,\n",
    "    rectify_image,\n",
    "    align_images_cv,\n",
    "    apply_perspective_scaling_and_skew,\n",
    "    align_image,\n",
    "    img_merge,\n",
    "    display_image_from_array,\n",
    "    read_calibration_params\n",
    ")\n",
    "        \n",
    "# ----------------------------\n",
    "# Configuration and File Paths\n",
    "# ----------------------------\n",
    "img_folder = root_path+\"/MM5_RAW/\"\n",
    "imgID = 69  # Example image ID\n",
    "\n",
    "# Construct file paths using glob patterns\n",
    "rgb_files    = glob.glob(os.path.join(img_folder, \"RGB_0\", f\"{imgID}_3_*_rgb.png\"))\n",
    "lwir_files   = glob.glob(os.path.join(img_folder, \"LWIR\", f\"{imgID}_*_lwir.png\"))\n",
    "lwir16_files = glob.glob(os.path.join(img_folder, \"LWIR\", f\"{imgID}_*_lwir16.png\"))\n",
    "\n",
    "if not rgb_files or not lwir_files or not lwir16_files:\n",
    "    print(\"Required images not found.\")\n",
    "    exit(1)\n",
    "\n",
    "print(rgb_files)\n",
    "# ----------------------------\n",
    "# Load Images\n",
    "# ----------------------------\n",
    "rgb_img    = cv2.imread(rgb_files[0], cv2.IMREAD_COLOR)\n",
    "lwir_img   = cv2.imread(lwir_files[0], cv2.IMREAD_UNCHANGED)\n",
    "lwir16_img = cv2.imread(lwir16_files[0], cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "# ----------------------------\n",
    "# Process Thermal Images\n",
    "# ----------------------------\n",
    "# Adjust tone and convert 16-bit thermal to 8-bit for processing\n",
    "imgT_norm = auto_tone(lwir16_img, 0.5, 99.5, None, 2)\n",
    "\n",
    "# Use the RGB image dimensions for further processing\n",
    "imageSize = (rgb_img.shape[1], rgb_img.shape[0])\n",
    "\n",
    "# ----------------------------\n",
    "# Read Calibration Data\n",
    "# ----------------------------\n",
    "calib_folder = root_path+\"/MM5_CALIBRATION/\"\n",
    "# Load calibration parameters for the thermal modality\n",
    "cal_dataT = read_calibration_params(calib_folder+\"def_stereocalib_THERM.yml\", 'stereo')\n",
    "cam_dataT = read_calibration_params(calib_folder+\"def_thermalcam_ori.yml\", 'cam')\n",
    "\n",
    "# ----------------------------\n",
    "# Rectify the Thermal Image\n",
    "# ----------------------------\n",
    "# Rectify both the LWIR image and the tone-adjusted thermal image\n",
    "imgT_rectified, _   = rectify_image(lwir_img, cam_dataT['CM'], cam_dataT['D'], imageSize)\n",
    "imgT8_rectified, _  = rectify_image(imgT_norm, cam_dataT['CM'], cam_dataT['D'], imageSize)\n",
    "\n",
    "# ----------------------------\n",
    "# Align Thermal to RGB\n",
    "# ----------------------------\n",
    "# Define alignment parameters (set to identity/zero for this minimal example)\n",
    "rotT = 0.2            # rotation\n",
    "udistAlpha = 0.55    # scaling\n",
    "shift_x = -28        # horizontal shift\n",
    "shift_y = -1         # vertical shift\n",
    "\n",
    "# Align the rectified thermal image to the RGB frame using calibration matrices\n",
    "imgT_aligned, map_x, map_y = align_images_cv(\n",
    "    cal_dataT['CM1'], cal_dataT['D1'],\n",
    "    cal_dataT['CM2'], cal_dataT['D2'],\n",
    "    cal_dataT['R'], rotT, cal_dataT['T'],\n",
    "    rgb_img, imgT_rectified, udistAlpha\n",
    ")\n",
    "\n",
    "# Optionally apply a perspective transform \n",
    "pTransT = [1.0, 1.0, 0, 0, 0, 0]\n",
    "# post transformation for adjustments\n",
    "imgT_transf  = apply_perspective_scaling_and_skew(imgT_aligned, pTransT[0],pTransT[1],pTransT[2],pTransT[3],pTransT[4],pTransT[5]);\n",
    "\n",
    "# A final alignment step to adjust thermal image positioning\n",
    "imgFinalT = align_image(rgb_img, imgT_transf, shift_x, shift_y, 1.0, 0.0, True)\n",
    "\n",
    "# ----------------------------\n",
    "# Merge Thermal with RGB for Visualization\n",
    "# ----------------------------\n",
    "# Overlay the thermal image on the RGB image using a weighted blend.\n",
    "weight = 60  # RGB image weight for overlay\n",
    "merged_imgT = img_merge(rgb_img, imgFinalT, weight, shift_x, shift_y, 1.0, 0.0, False, False, True)\n",
    "                       \n",
    "# ----------------------------\n",
    "# Display Results\n",
    "# ----------------------------\n",
    "display_image_from_array(rgb_img, title=\"RGB Image\")\n",
    "display_image_from_array(imgFinalT, title=\"Aligned Thermal Image\")\n",
    "display_image_from_array(merged_imgT, title=\"Merged RGB & Thermal Image\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e97ecae",
   "metadata": {},
   "source": [
    "## Label Re-Projection (MAR)\n",
    "Please note that the minimum working example below uses hard-coded correction values for depth correction. The value of reTransT must be adjusted for different positions during bulk processing, as the corresponding correction matrix is not currently provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccdd11f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import json\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import importlib\n",
    "\n",
    "# Clear module cache for mm5_ls_utils (useful during development)\n",
    "modules_to_clear = ['mm5_ls_utils']\n",
    "for module in modules_to_clear:\n",
    "    if module in sys.modules:\n",
    "        del sys.modules[module]\n",
    "        importlib.invalidate_caches()\n",
    "\n",
    "from mm5_ls_utils import (\n",
    "    get_depth,\n",
    "    process_images,\n",
    "    convert_bin2gray,\n",
    "    get_region_growing,\n",
    "    refine_map_with_region_growing,\n",
    "    apply_color_to_binary_map,\n",
    "    img_merge,\n",
    "    display_image_from_array,\n",
    "    read_calibration_params,\n",
    "    align_images_cv,\n",
    "    check_color_borders,\n",
    "    rectify_image\n",
    ")\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# Configuration and Paths\n",
    "# -------------------------------------------------------------------------\n",
    "img_folder   = os.path.join(root_path, \"MM5_RAW\")\n",
    "anno_folder  = os.path.join(img_folder, \"ANNO_V\")\n",
    "calib_folder = os.path.join(root_path, \"MM5_CALIBRATION\")\n",
    "\n",
    "imgID = 353  # Example image ID\n",
    "do_debug = True\n",
    "\n",
    "# Calibration file paths\n",
    "cal_stereo_thermal = os.path.join(calib_folder, \"def_stereocalib_THERM.yml\")\n",
    "cal_thermal_cam    = os.path.join(calib_folder, \"def_thermalcam_ori.yml\")\n",
    "cal_rgb_cam        = os.path.join(calib_folder, \"def_rgbcam_ori.yml\")  # Optional\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# Load Depth Image & Annotation Metadata; Get Depth Values & Annotation Maps\n",
    "# -------------------------------------------------------------------------\n",
    "depth_pattern = os.path.join(img_folder, \"DEPTH_0\", f\"{imgID}_*_depth_tr.png\")\n",
    "depth_files = glob.glob(depth_pattern)\n",
    "if not depth_files:\n",
    "    raise FileNotFoundError(f\"No depth image found for pattern: {depth_pattern}\")\n",
    "depth_img = cv2.imread(depth_files[0], cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "json_file_path = os.path.join(anno_folder, \"label_instances.json\")\n",
    "with open(json_file_path, \"r\") as f:\n",
    "    metadata = json.load(f)\n",
    "\n",
    "# get_depth returns (depthValues, imgAC_colored, imgAO_colored)\n",
    "depthValues, imgAC_colored, imgAO_colored = get_depth(imgID, depth_img, anno_folder, metadata)\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# Load RAW RGB and Thermal Images\n",
    "# -------------------------------------------------------------------------\n",
    "rgb_pattern   = os.path.join(img_folder, \"RGB_0\", f\"{imgID}_*_rgb.png\")\n",
    "lwir_pattern  = os.path.join(img_folder, \"LWIR\", f\"{imgID}_*_lwir.png\")\n",
    "\n",
    "rgb_files  = glob.glob(rgb_pattern)\n",
    "lwir_files = glob.glob(lwir_pattern)\n",
    "if not rgb_files:\n",
    "    raise FileNotFoundError(f\"No RGB image found for pattern: {rgb_pattern}\")\n",
    "if not lwir_files:\n",
    "    raise FileNotFoundError(f\"No thermal image found for pattern: {lwir_pattern}\")\n",
    "\n",
    "raw_rgb_img  = cv2.imread(rgb_files[0], cv2.IMREAD_COLOR)\n",
    "raw_lwir_img = cv2.imread(lwir_files[0], cv2.IMREAD_UNCHANGED)\n",
    "(h_rgb, w_rgb) = raw_rgb_img.shape[:2]\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# Rectify Thermal Image (and use raw RGB directly)\n",
    "# -------------------------------------------------------------------------\n",
    "cam_dataT = read_calibration_params(cal_thermal_cam, 'cam')\n",
    "rect_lwir_img, _ = rectify_image(raw_lwir_img, cam_dataT['CM'], cam_dataT['D'], (w_rgb, h_rgb))\n",
    "rect_rgb_img = raw_rgb_img  # Use raw RGB if rectification is not required\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# Align Thermal to RGB using Stereo Calibration\n",
    "# -------------------------------------------------------------------------\n",
    "cal_dataT = read_calibration_params(cal_stereo_thermal, 'stereo')\n",
    "rotT = 0.2          # Example rotation angle\n",
    "udistAlpha = 0.55   # Example scaling factor\n",
    "reTransT = [0.1, 47, -2, 1.08, 0.2, False, True, False]  # Transformation parameters\n",
    "pTransT = [1.0, 1.0, 0, 0, 0, 0]  # Post perspective transform parameters\n",
    "\n",
    "imgT_aligned, map_x, map_y = align_images_cv(\n",
    "    cal_dataT['CM1'], cal_dataT['D1'],\n",
    "    cal_dataT['CM2'], cal_dataT['D2'],\n",
    "    cal_dataT['R'], rotT, cal_dataT['T'],\n",
    "    rect_rgb_img, rect_lwir_img, udistAlpha\n",
    ")\n",
    "imgT_transf = apply_perspective_scaling_and_skew(imgT_aligned, *pTransT)\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# Check Annotation Overlap and Prepare Data for Reprojection\n",
    "# -------------------------------------------------------------------------\n",
    "overlapAO = check_color_borders(imgAO_colored, 30)\n",
    "if do_debug:\n",
    "    print(\"OVERLAP\" if overlapAO else \"NO OVERLAP\")\n",
    "\n",
    "# Initialize temporary arrays and set parameters for annotation warping\n",
    "imgAC_unrecT = np.zeros((480, 640, 3), dtype=np.uint8)\n",
    "imgAC_unrecUV = np.zeros((560, 720, 3), dtype=np.uint8)\n",
    "valx, valy = (0.5, 0.5)\n",
    "imgM = auto_tone(raw_lwir_img, 0.5, 99.5, None, 2)\n",
    "reTrans = reTransT\n",
    "weight = 60\n",
    "\n",
    "if do_debug:\n",
    "    display_image_from_array(imgAO_colored, \"imgAO_colored\")\n",
    "    merged_imgT = img_merge(raw_rgb_img, imgT_transf, weight, -62, -2, 1.0, 0.0, False, False, True)\n",
    "    merged_imgT = img_merge(merged_imgT, imgAO_colored, weight, 0, 0, 1.0, 0.0, False, False, True)\n",
    "    display_image_from_array(merged_imgT, \"merged_imgT\")\n",
    "\n",
    "# Warp the annotation maps into the thermal coordinate system\n",
    "imgAC_unrecT, imgAO_unrecT = process_images(\n",
    "    imgAC_colored, imgAO_colored, map_x, map_y, cam_dataT, imgM, valx, valy\n",
    ")\n",
    "mergedAC_imgT = img_merge(imgM, imgAC_unrecT, *reTrans)\n",
    "imgAC_unrecT = apply_perspective_scaling_and_skew(imgAC_unrecT, *pTransT)\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# Process Each Annotated Instance for Refinement\n",
    "# -------------------------------------------------------------------------\n",
    "combined_instance_mapT = np.zeros_like(mergedAC_imgT, dtype=np.uint8)\n",
    "combined_class_mapT = np.zeros_like(mergedAC_imgT, dtype=np.uint8)\n",
    "combined_colored_mapT = np.zeros((mergedAC_imgT.shape[0], mergedAC_imgT.shape[1], 3), dtype=np.uint8)\n",
    "labelMask = np.zeros((mergedAC_imgT.shape[0], mergedAC_imgT.shape[1]), dtype=np.uint8)\n",
    "\n",
    "unknown_areas = {}\n",
    "eroded_areas = {}\n",
    "object_ed = {}\n",
    "object_instanceMap = {}\n",
    "MAX_ED = 8\n",
    "\n",
    "for idx, (key, value) in enumerate(depthValues):\n",
    "    current_id = f\"{key[1]}_{key[2]}\"\n",
    "    instanceMap = value['binary_map']\n",
    "    image_id = key[0]\n",
    "    # Warp the instance map using the same mapping\n",
    "    _, instanceMap = process_images(instanceMap, instanceMap, map_x, map_y, cam_dataT, imgM, valx, valy)\n",
    "    instanceMapSize = np.sum(instanceMap)\n",
    "    # Merge with a binary conversion for consistency\n",
    "    instanceMap = img_merge(imgM, convert_bin2gray(instanceMap), 0,*reTrans[1:])\n",
    "    object_instanceMap[current_id] = instanceMap\n",
    "\n",
    "    # Compute erosion iterations based on instance map size\n",
    "    ed = int(max(min(np.sqrt(instanceMapSize) / 600, MAX_ED), 1))\n",
    "    object_ed[current_id] = ed\n",
    "    if do_debug:\n",
    "        print(f\"IM size: {instanceMapSize}; ed: {ed}\")\n",
    "\n",
    "    # Compute 'unknown' regions using region growing\n",
    "    unknown, eroded = get_region_growing(imgM, instanceMap, walker_iterations=1+ed, seedErode=3+ed)\n",
    "    unknown_areas[current_id] = unknown\n",
    "    eroded_areas[current_id] = eroded\n",
    "\n",
    "# For each instance, refine the segmentation using information from other instances\n",
    "for idx, (key, value) in enumerate(depthValues):\n",
    "    current_id = f\"{key[1]}_{key[2]}\"\n",
    "    shape = unknown_areas[current_id].shape\n",
    "    other_unknown = np.zeros(shape, dtype=np.uint8)\n",
    "    other_eroded = np.zeros(shape, dtype=np.uint8)\n",
    "\n",
    "    # Merge unknown and eroded regions from other instances\n",
    "    for other_id, unk_area in unknown_areas.items():\n",
    "        if other_id != current_id:\n",
    "            other_unknown = cv2.bitwise_or(other_unknown, unk_area)\n",
    "    for other_id, erd_area in eroded_areas.items():\n",
    "        if other_id != current_id:\n",
    "            other_eroded = cv2.bitwise_or(other_eroded, erd_area)\n",
    "\n",
    "    rgb_color = value['instance_colour']\n",
    "    instanceMap = object_instanceMap[current_id]\n",
    "    ed = object_ed[current_id]\n",
    "\n",
    "    # Refine the instance map using region growing refinement\n",
    "    debugImg, refined_map, label, gray_image, edges = refine_map_with_region_growing(\n",
    "        imgM, instanceMap, other_unknown, other_eroded,\n",
    "        beta=50, mode='bf', canny_threshold1=130, canny_threshold2=190,\n",
    "        walker_iterations=1+ed, refined_iterations=2+ed, seedErode=1+ed,\n",
    "        growDilate=3+ed, grayPctMin=0, grayPctMax=97, disableCanny=overlapAO, otherErode=3\n",
    "    )\n",
    "\n",
    "    # Update label mask and store refined map in metadata\n",
    "    labelMask[label == 2] = 255\n",
    "    value['label_maskT'] = refined_map.copy()\n",
    "\n",
    "    # Apply color mapping to the refined segmentation map\n",
    "    refined_map_colored = apply_color_to_binary_map(refined_map, rgb_color)\n",
    "\n",
    "    if do_debug:\n",
    "        display_image_from_array(debugImg, f\"debugImg T = IM size: {instanceMapSize}; ed: {ed}\")\n",
    "\n",
    "    # Update combined maps for visualization\n",
    "    combined_instance_mapT[label == 2] = key[2]\n",
    "    combined_class_mapT[label == 2] = key[1]\n",
    "    combined_colored_mapT[label == 2] = rgb_color\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# Display Combined Results (if debugging)\n",
    "# -------------------------------------------------------------------------\n",
    "if do_debug:\n",
    "    gray_img = cv2.cvtColor(imgM, cv2.COLOR_BGR2GRAY)\n",
    "    mergedAOI_imgT = img_merge(gray_img, combined_colored_mapT, reTransT[0], 0, 0, 1.0, 0.0, False, True, False)\n",
    "    mergedAO_imgT = img_merge(gray_img, imgAO_unrecT, *reTransT)\n",
    "    display_image_from_array(mergedAO_imgT, \"mergedT\")\n",
    "    display_image_from_array(mergedAOI_imgT, \"merged IMPROVED\")\n",
    "    display_image_from_array(combined_colored_mapT, \"Combined Colored Map T\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35740c37",
   "metadata": {},
   "source": [
    "## Thermal processing 16 to 24bit (DTMRE)\n",
    "### With stabilised temperature\n",
    "We offset measurement errors of the camera by comparing the temperature in a specific area."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d7b2d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import sys\n",
    "\n",
    "# Clear previously loaded modules if necessary\n",
    "modules_to_clear = ['mm5_t24encoding', 'mm5_ls_utils', 'mm5_d16to8.py']\n",
    "for module in modules_to_clear:\n",
    "    sys.modules.pop(module, None)\n",
    "\n",
    "# Import the custom functions and classes\n",
    "from mm5_d16to8 import *\n",
    "from mm5_t24encoding import *\n",
    "\n",
    "# Create the colour map \n",
    "cm = ColourMap()\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# Define dataset paths and parameters\n",
    "# -------------------------------------------------------------------------\n",
    "dataset_folder = os.path.join(root_path, \"MM5_RAW\")\n",
    "data_folder = os.path.join(dataset_folder, \"LWIR\")  # Folder with depth images\n",
    "test_img = \"548_\"          # Process only images starting with this string; leave empty to process all\n",
    "doStabilize = True         # Whether to stabilize the image by offsetting values\n",
    "probe_size = 9             # Size of the probe square for stabilization\n",
    "base_temp = 18310          # Base temperature value used for offsetting camera fluctuations\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# Process each LWIR16 PNG file in the data folder\n",
    "# -------------------------------------------------------------------------\n",
    "for file_path in glob.glob(os.path.join(data_folder, '*lwir16.png')):\n",
    "    filename = os.path.basename(file_path)\n",
    "    # If test_img is defined, process only matching files\n",
    "    if test_img and not filename.startswith(test_img):\n",
    "        continue\n",
    "\n",
    "    print(f\"Processing file: {file_path}\")\n",
    "    data_array = cv2.imread(file_path, cv2.IMREAD_UNCHANGED)\n",
    "    if data_array is None:\n",
    "        print(\"Failed to load image.\")\n",
    "        continue\n",
    "\n",
    "    # ---------------------------------------------------------------------\n",
    "    # Stabilize the image based on the bottom-center probe square\n",
    "    # ---------------------------------------------------------------------\n",
    "    if doStabilize:\n",
    "        height, width = data_array.shape[:2]\n",
    "        if height < probe_size or width < probe_size:\n",
    "            raise ValueError(\"Image dimensions are smaller than the probe size.\")\n",
    "\n",
    "        # Determine the bottom-center probe square indices\n",
    "        start_row = height - probe_size\n",
    "        start_col = width // 2 - probe_size // 2\n",
    "\n",
    "        # Extract probe square and compute its average value\n",
    "        probe_square = data_array[start_row:, start_col:start_col + probe_size]\n",
    "        avg_value = int(np.mean(probe_square))\n",
    "        print(\"Average value (int) of bottom middle probe square:\", avg_value)\n",
    "\n",
    "        # Calculate difference and adjust the entire image\n",
    "        difference = base_temp - avg_value\n",
    "        print(\"Difference to apply:\", difference)\n",
    "        data_array = data_array.astype(np.int32) + difference\n",
    "        data_array = np.clip(data_array, 0, 65535).astype(np.uint16)\n",
    "\n",
    "    # ---------------------------------------------------------------------\n",
    "    # Convert raw depth values to temperature in Celsius and apply colour map\n",
    "    # ---------------------------------------------------------------------\n",
    "    # The conversion formula: (raw/64) - 273.15\n",
    "    temp_celsius_array = (data_array / 64) - 273.15\n",
    "\n",
    "    # Apply the colour map for each temperature value\n",
    "    rgb_colors = np.array([cm.get_temperature_color(temp) for temp in temp_celsius_array.ravel()])\n",
    "    # Reshape the resulting colors to match the original image dimensions (with 3 channels)\n",
    "    data_img = rgb_colors.reshape((*data_array.shape, 3))\n",
    "\n",
    "    # ---------------------------------------------------------------------\n",
    "    # Display the processed image\n",
    "    # ---------------------------------------------------------------------\n",
    "    plt.imshow(data_img)\n",
    "    plt.title(filename)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d479cb",
   "metadata": {},
   "source": [
    "## Generate coloured depth focus image (ADMRE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2b0070",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import importlib\n",
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from scipy.signal import find_peaks\n",
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "# Clear previously loaded modules for mm5_d16to8 and mm5_depthCorrect\n",
    "modules_to_clear = ['mm5_d16to8']\n",
    "for module in modules_to_clear:\n",
    "    sys.modules.pop(module, None)\n",
    "\n",
    "from mm5_d16to8 import *\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# Configuration and Parameters\n",
    "# -------------------------------------------------------------------------\n",
    "dataset_folder = os.path.join(root_path, \"MM5_ALIGNED\")\n",
    "depth_folder = os.path.join(dataset_folder, \"D16\")\n",
    "\n",
    "test_img = \"259\"         # Process only this single image (filename (id) without extension)\n",
    "debug    = True          # Debug flag for additional output\n",
    "debugDepthvals = True    # Additional debug output\n",
    "       # Apply inpainting to fix missing depth measurements\n",
    "\n",
    "# Processing parameters\n",
    "num_channels   = 2       # 1: single channel 8-bit; 2: dual-channel RG (B=normals)\n",
    "do_normals     = True    # If True, add normals to the output image\n",
    "doInpaint      = True    # inpaint\n",
    "inpaint_radius = 5\n",
    "ol_threshold   = 0       # minimum pixel count for depth level - pixels dropped if below. \n",
    "min_width      = 50      # peak settings\n",
    "max_width      = 150     # peak settings\n",
    "min_focus      = 400     # minimum distance for focus\n",
    "max_focus      = 900     # maximum distance for focus\n",
    "res_oof_near   = 6       # resolutin\n",
    "res_oof_far    = 6\n",
    "res_gap        = 2\n",
    "res_focus      = 1\n",
    "vd_min         = 200     # Minimum valid depth value\n",
    "\n",
    "useKDE = True # use KDE or approximation\n",
    "num_peaks = 5\n",
    "num_buckets = 100 # lower values like 40 for KDE\n",
    "# for approximation implementation (if useKDE=False)\n",
    "sigma_value=0.6\n",
    "min_height = 0.00002       # Minimum height of a peak\n",
    "min_prominence = 0.00005    # Minimum prominence of a peak\n",
    "min_distance = 15\n",
    "# -------------------------------------------------------------------------\n",
    "# Locate and Load the Test Image\n",
    "# -------------------------------------------------------------------------\n",
    "file_pattern = os.path.join(depth_folder, f\"{test_img}.png\")\n",
    "files = glob.glob(file_pattern)\n",
    "if not files:\n",
    "    raise FileNotFoundError(f\"Test image not found: {file_pattern}\")\n",
    "file_path = files[0]\n",
    "print(f\"Processing file: {file_path}\")\n",
    "\n",
    "depth_array = cv2.imread(file_path, cv2.IMREAD_UNCHANGED)\n",
    "if depth_array is None:\n",
    "    raise ValueError(f\"Failed to load image: {file_path}\")\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# Inpaint Missing Depth Values (If Enabled)\n",
    "# -------------------------------------------------------------------------\n",
    "if doInpaint:\n",
    "    mask = (depth_array == 0).astype(np.uint8)\n",
    "    depth_array = cv2.inpaint(depth_array, mask, inpaintRadius=inpaint_radius, flags=cv2.INPAINT_NS)\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# Run the Focus/Depth Processing\n",
    "# -------------------------------------------------------------------------\n",
    "depth_img_focus = getDepth(\n",
    "    depth_array, os.path.basename(file_path), debug, ol_threshold, min_width, max_width, min_focus, max_focus, res_oof_near, res_oof_far, res_gap, res_focus, num_channels,\n",
    "    num_peaks,\n",
    "    num_buckets,\n",
    "    sigma_value,      # sensitivity\n",
    "    min_height,       # Minimum height of a peak\n",
    "    min_prominence,   # Minimum prominence of a peak\n",
    "    min_distance,     # Minimum number of points between peaks\n",
    "    useKDE\n",
    ")\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# Additional debug output with histograms\n",
    "# -------------------------------------------------------------------------\n",
    "\n",
    "if debugDepthvals:\n",
    "    showDepth(depth_array,filename, False, True, False, inpaint_radius, ol_threshold , min_width, max_width, min_focus, max_focus\n",
    "                            , res_oof_near, res_oof_far, res_gap, res_focus, num_channels,num_peaks, num_buckets,\n",
    "    sigma_value,      # sensitivity\n",
    "    min_height,       # Minimum height of a peak\n",
    "    min_prominence,   # Minimum prominence of a peak\n",
    "    min_distance,     # Minimum number of points between peaks\n",
    "    useKDE)\n",
    "    valid_depths = depth_array[depth_array > 0]\n",
    "\n",
    "    print(f\"Depth min/max: {valid_depths.min()}/{valid_depths.max()}\")\n",
    "    valid_depths = depth_array[depth_array > 0]\n",
    "\n",
    "    # Calculate min and max from non-zero values\n",
    "    if valid_depths.size > 0:\n",
    "        depth_min = valid_depths.min()\n",
    "        depth_max = valid_depths.max()\n",
    "    else:\n",
    "        depth_min = None  # No valid depths available\n",
    "        depth_max = None\n",
    "\n",
    "    # Calculate how many values are within the range 1-100\n",
    "    count_in_range = np.sum((depth_array >= 1) & (depth_array <= vd_min))\n",
    "\n",
    "    # Print detailed debug information\n",
    "    print(f\"Depth min/max (excluding zeros): {depth_min}/{depth_max}\")\n",
    "    print(f\"Number of values in the range 1-100: {count_in_range}\")\n",
    "    range_mask = (depth_array >= 1) & (depth_array <= vd_min)\n",
    "\n",
    "    # Check if there are any values in the range\n",
    "    if np.any(range_mask):\n",
    "        plt.figure(figsize=(10, 6))  # Set the figure size for better visibility\n",
    "        plt.imshow(range_mask, cmap='gray')  # Use a gray colormap to show the mask\n",
    "        plt.colorbar()  # Add a colorbar to help identify the mask\n",
    "        plt.title('Mask of Depth Values Between 1 and 100')\n",
    "        plt.xlabel('X Pixel')\n",
    "        plt.ylabel('Y Pixel')\n",
    "        plt.show()\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# Merge Normals if Needed and Display\n",
    "# -------------------------------------------------------------------------\n",
    "title_pf = \" +N\" if do_normals else \"\"\n",
    "\n",
    "if num_channels == 1:\n",
    "    # Single-channel grayscale depth\n",
    "    depth_gray = Image.fromarray(depth_img_focus, mode='L')  # 'L' for 8-bit grayscale\n",
    "    if do_normals:\n",
    "        nrm = normals_to_grayscale(depth_array, sobel_kernel_size=7, smoothing_kernel_size=(7, 7)) * 0.8\n",
    "        nrm = np.clip(nrm, 0, 255).astype(np.uint8)\n",
    "        nrm_img = Image.fromarray(nrm, mode='L')\n",
    "        depth_img = Image.blend(depth_gray, nrm_img, alpha=0.3)\n",
    "    else:\n",
    "        depth_img = depth_gray\n",
    "\n",
    "    # Display the single-channel image\n",
    "    plt.imshow(depth_img, cmap='gray')\n",
    "    plt.title('Focus Depth 8-bit' + title_pf)\n",
    "    plt.colorbar(label='Depth')\n",
    "\n",
    "elif num_channels == 2:\n",
    "    # Dual-channel RG image (blue=0) plus optional normals in B channel\n",
    "    depth_img_rg = np.zeros((depth_img_focus.shape[0], depth_img_focus.shape[1], 3), dtype=np.uint8)\n",
    "    depth_img_rg[..., 0:2] = depth_img_focus[..., 0:2]\n",
    "    if do_normals:\n",
    "        nrm = normals_to_grayscale(depth_array, sobel_kernel_size=7, smoothing_kernel_size=(9, 9)) * 0.8\n",
    "        nrm = np.clip(nrm, 0, 255).astype(np.uint8)\n",
    "        depth_img_rg[..., 2] = nrm\n",
    "\n",
    "    depth_img = Image.fromarray(depth_img_rg)\n",
    "    plt.imshow(depth_img)\n",
    "    plt.title('Focus Depth Dual Channel RG' + title_pf)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(\"Focused depth image processed successfully!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
